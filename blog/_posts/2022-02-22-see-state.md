---
title: "How smart developers make bad strageic decisions"
categories:
  - Articles
author: Adam
featured: true
sidebar:
  nav: "thoughts"
---
### Writing Article Checklist

- [ ] Write Outline
- [ ] Write Draft
- [ ] Fix Grammarly Errors
- [ ] Read out loud
- [ ] Write 5 or more titles and pick the best on
- [ ] First two paragraphs: What's it about? Why listen to you?
- [ ] Create header image in Canva
- [ ] Optional: Find ways to break up content with quotes or images
- [ ] Verify look of article locally
- [ ] Run mark down linter (`lint`)
- [ ] Add keywords for internal links to front-matter
- [ ] Run `link-opp` and find 1-5 places to incorporate links to other articles
- [ ] Add Earthly `CTA` at bottom `{% include cta/cta1.html %}`
- [ ] Raise PR

Sometimes smart people working hard make things worse. Here is a simplification of a true story:

## Scheduling Work Problems

A group of data processing services are struggling under increased load. Some clients are never getting their results, because other busier clients are clogging up the queue and starving them out. The problem is like an operating system scheduling problem but in a micro-services, distributed system context.

<div class="align-right">
 {% picture gridnc {{site.pimages}}{{page.slug}}/3530.png --picture --img width="200px" --alt {{ I need this fixed, yesterday }} %}
</div>

It's causing the worst kind of problems: people problems – the kind of problems where an executive who didn't know this service existed is now requesting daily updates on it.

In turns out this service is using a postgres table and Kafka topics for scheduling. And there are lots of variables to tweak to get the right combination of through-put and fairness. Scheduling is hard. So calls go out: who can help with this system? Other developers in the company who do similar work aren't familiar with Kafka. Best to just let the people who know the system work to improve it.

So the problem is worked out – or rather a compromise between fairness and throughput is acheived - but in an effort to prevent further incidents, someone on the architecture team starts investigating how queuing and work in progress is handled among the hundred plus services at the company. 

It turns the answer is: in all of the possible ways. But mainly its being done using SQS, a database table, or Kafka.

<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/7520.png --alt {{  }} %}
<figcaption>From the outside the solution seemed [a bit complicated](https://www.youtube.com/watch?v=y8OnoxKotPQ)</figcaption>
</div>

## A Solution

So a solution was proposed. A common library will be created and you can use it for all your queuing and message processing needs. It will be backed by Kafka and everybody will move to it.

{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/4070.png --alt {{  }} %}
<figcaption>It would be simpler if everything were standardized, Right?</figcaption>

The beauty of this solution is that everything will work the same. If one team working on one service solves some work-starving problem, others can use the solution, because its a common lib. And if things go wrong in one area, people from other areas can lend a hand, because its all the same solution everywhere.

Actually, it didn't work out like that at all.

## How Things Failed

Every service that processed data was doing things in a slightly different way and that made the system as a whole hard to understand from a top down perspective. And sure some of these various sub systems had problems. The hypothesis was that by standardizing things many of these little unrelated problems, including the initial faireness problem could be solved all at once. 

But, that hypothesis turned out to be wrong. So wrong that there is a great book written all about this type of error.

<div class="notice--info">
**Side Note: Kafka**

I think picking Kafka was a tactical error here, because its a bad fit for being a work queue, but there were uninteresting, extenuating circumstances, that made it seem like a good fit. 

The larger issue though, that I'd like to explore is pursuing standardization as its own end.

</div>

## Seeing Like a State

"Seeing like a state - How certain schemes to improve the human condition have failed" is about one thing: how centrally planned, top down schemes to improve the world have failed. It covers a lot of centralized standardization efforts and they all have a lot in common and sound a lot like this 'unify the queues' effort.

### Scientific Forestry

In the 1800s, in Europe, forests were important sources of revenue. A tree could be timber and a tree could be firewood and each acre of forest a country owned was valuable. But how valuable?

The problem with an acre of forests is it contains random trees in a random pattern. Its illegible. You can't really understand at high level what trees you have. You could make a map of it, but it would be hard and the map would be very complex. 

<div class="align-left">
{% picture grid {{site.pimages}}{{page.slug}}/3260.png --img width="300px" --alt {{ forest }} %}  
<figcaption>Reality is a mess</figcaption>
</div>

There are lots of different types of trees, which all might be useful for different things. Reality it turns out is a mess. 

So the solution was scientific forestry. Let's make a map of a simplified forest, where it just has the best type of tree and we'll make the whole forest that. It turns out the best tree was a norway spruce. 

This went poorly:

> The impoverished ecosystem couldn’t support the game animals and medicinal herbs that sustained the surrounding peasant villages, and they suffered an economic collapse. The endless rows of identical trees were a perfect breeding ground for plant diseases and forest fires. And the complex ecological processes that sustained the soil stopped working, so after a generation the Norway spruces grew stunted and malnourished. [^1]

<div class="align-right">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/3760.png --img width="300px" --alt {{ a tree plantation }} %}
<figcaption>A Tree Plantation</figcaption>
</div>

And you would think that would end things, but managed tree plantations are still popular. And central planning things in a way that looks very uniform on a diagram but doesn't work well in practise continues to this day.


James C. Scott calls these top down systems legible. They are simple to explain at a high level. How does work get processed in that service? The same was as in every other service. What type of tree is that in the forest? It is a norway spruce, same as all the other trees.

> This is the opposite of building a map from the territory. 
>
> This is saying let’s take our map and make the territory more like it. [^2]

The problem from Scott's perspective is that this push for standarization throws out lots of local, tacit know how in favor of a system that optimizes for top down control.

> let us say, for the sake of simplicity, a fence or gate erected across a road. The more modern type of reformer goes gaily up to it and says, “I don’t see the use of this; let us clear it away.” To which the more intelligent type of reformer will do well to answer: “If you don’t see the use of it, I certainly won’t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.”
>
> - Chesterton's Fence

Standardization ignores Chesterton's Fence. Why did cities develop to have mixed use zones? Why did this service use a simple database table for queuing? why do Norway spruce not normally grow here? You need to know the answers to those questions.

## This is Hard

Seeing like a State goes through a lot of examples of this problem. Grid plan Cities, modern zoning and large scale architecture all repeated the mistakes of scientific forestry, from his perspective. And the mistake is easy to state: it's trying to make the territory match a map and forgetting the map ( or architecture diagram ) is just a map. There are many local conditions on the ground that aren't reflected in the map.

I don't mean to say this a silly mistake no one should make. It's easy to make. If you go out to understand the way N number of services handle work in progress there is a lot of details. The way we as humans make sense of these things is abstract and group things together. What is common between how all these services do things? You build up an understanding and then with that understanding you try to come up with a solution.

What Seeing like a State tells us is that the problem might be trying to come up with a global solution. A global solution, but necessity has to ignore local conditions. 

Going back to the queue example, If the architect or senior++ principle engineer instead embedded with a team, and worked to solve that specific problem, and then embedded with another team and solved another specific problem, then some commonalities may have emerged. Or maybe not, maybe each problem would need a different solution. Embedding with specific teams you get to learn the conditions on the ground. Lots of it doens't matter, but some of it does.

>The vast majority of knowledge of how the system works is not contained in any book—it’s not contained in some expert’s head—it’s interwoven in heads of all the people who participate in the system. 
>
>It’s not just an idea of grand architects for human society… there’s a huge body of local know-how that isn’t really written down anywhere. [^2]

So, top down standardization bad. Collaboritive, temporailly embedded experts good. 

Top down standaridization invetibly misses all the tacit details on the ground. Collaboritive empowerment works in the context of the actual problem. The book is better than that, but that is my summary. 
---
extra stuff
## Making the Territory Fit The Map

So what happened here was this:

1) Someone noticed something was hard to understand at a global, top down view. 
2) They embarked on a project to standardize things hoping it would simplify work going forward.

The problem is the architecture diagrams goal was to help people understand what the various did things. It was a map, but there no reason to think that making the map easier to understand would fix any problems besides making it more understandable what was going on at a high-level. There was no reason to think it would make the work easier.

--one could But this wasn't actually a problem developers on the ground were having. Most people worked in a small handful of areas, and had time to get familar with how things worked in that specific area. 




Standardizing the way things were made the architecture diagram a lot easier to understand and theorically made it easier to move from area to area, but engineers are not interchangeable, people have strengths and weakness and if people need to moved around rapidly from one area of the business to another maybe that is more of an organizational problem than an architecture problem.

The new diagram looks pretty and its easier to understand. It's much easier to step into a service and know how its going to work. But that wasn't a problem anyone working on these services said they were having. At the ground level, someone working on a service that pulled some work from a SQS queue and now had to move to Kafka and that was a big change. 


---

### Domain Driven Garbage

Once I noticed this pattern, in seeing like a state I started noticing how often it had occured. Years ago I worked on large monolithic system where the rate of change had started to slow down. So some very smart people took a look at it and decided that the problem was it didn't follow DDD princinples. The business logic and the retrival logic and whatever other areas all needed to be kept seperate. The 'domain' was mapped out and changes were made.

Now I had read part of DDD book, and I thought it was pretty good. It was all about representing the concepts within your problem domain in the code. But I must have read it wrong, because the local experts interpreted it as being about representing the concepts of DDD within your code. Everything was an XEntity or XRepository or something called an Aggregate, which, according to wikipedia is either sand, gravel or crushed stone. I don't know.

However, I hit a problem with this when my team had to build something that needed data from two areas. Because of seperation of data retrival and business logic to get 100 rows of data required 101 requests. This is the classic N+1 problem and there are solutions to it. 

But the people with the domain glossary thought the problem was I was trying to cross bounded contexts, whatever that means, and you weren't supposed to do that. It's the same problem again. They were looking at the map and using it to point out a mistake in the territory, not realizing they had the arrow backwards.

Anyways, no one involved in any of these discussions was an idiot. They were just disconneted from what was happening on the ground. They were focused on a global top down view, not realizing that their understanding could be wrong - it was just a simplification.
---

[^1]:
  https://slatestarcodex.com/2017/03/16/book-review-seeing-like-a-state/
[^2]:
  https://www.scotthyoung.com/blog/2018/01/25/book-club-seeing-like-a-state-january-2018/

  