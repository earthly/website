Here is a 3 article series on python:

<one>
---
title: "Create a Python Package using Setup.py"
categories:
  - Tutorials
toc: true
author: Adam
sidebar:
  nav: "pypi"
---

Python has a vibrant open source ecosystem and that has been one of the keys to its popularity. As a Python developer, you can create reusable tools and code and easily share them with others. Packaging and publishing your Python code properly enables other developers to easily install and use your code in their own projects. This allows you to contribute back to the community while also building your reputation.

In this 3-part series, we'll cover packaging a simple Python script using setuptools and twine, then an alternative method using poetry, then we will extend what we learn to a C module, and finally we will publish it to PyPI. 

<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/5510.png --alt {{ Our Goal Today is to get this package onto PyPi }} %}
<figcaption>Our Goal Today is to get this package onto PyPi</figcaption>
</div>

In this first article, I'll show you how to package your Python code into distributions, and then publish those packages on PyPI (the Python Package Index) using setuptools and twine. Learning these skills will you level up your ability to produce professional, sharable Python software.

## Merge Lists Code

To start, we'll use the following simple Python code snippet as an example to package:

(See earlier article about [merge sorted lists](/blog/python-timsort-merge/) for background.) 

~~~{.python caption="core.py"}
def merge(list1, list2):
    merged_list = []
    i, j = 0, 0
    
    while i < len(list1) and j < len(list2):
        if list1[i] < list2[j]:
            merged_list.append(list1[i])
            i += 1
        else:
            merged_list.append(list2[j])
            j += 1
    
    # Add any remaining elements from list1 or list2
    while i < len(list1):
        merged_list.append(list1[i])
        i += 1
        
    while j < len(list2):
        merged_list.append(list2[j])
        j += 1
    
    return merged_list

~~~

Lets get that up on PyPI using `setuptools`.

( In [Part Two](/blog/poetry-publish/), we'll package it with Poetry and in [Part Three](/blog/python-c-extension/), we'll port the C version of the code to PyPi.)

First step is to find a name for our package.

## Choosing A Package Name

Originally, I had called this package `PyMerge`. There a number of problems with that, including that this name has been taken already.

You can check what already in use by searching around on [PyPI](https://pypi.org/). If you push a package that's already been taken you'll get this:

~~~
HTTP Error 403: The user 'adamgordonbell' isn't allowed to upload to ↩
project 'PyMerge'. 
See https://pypi.org/help/#project-name for more information.
~~~

The name being in used forced me to look for a new name and its a good thing I did because it turns out `PyMerge` is a horrible name. When selecting a name for your package, follow these rules set forth by the Python Packaging Authority (PyPA):

- **Keep It Short & Descriptive:** Names should be short, but also give a clear idea of what the package does. For example, requests is a popular library that makes HTTP requests.

- **Avoid Underscores:** Although underscores are allowed, dashes are more common in package names. However, note that the actual module or package inside might use underscores (e.g., the package `dateutil` on PyPI corresponds to the `date_util` module when imported in Python).

- **Avoid Uppercase Letters:** Lowercase names are conventional for package names. This makes them easy to type and avoids ambiguity on case-sensitive file systems.

- **Check for Name Availability:** Before finalizing a name, search on PyPI to ensure that the name isn't already taken. Even if it's available, avoid names that are too similar to existing packages to prevent confusion.

- **Avoid Generic Names:** Names that are too generic can be misleading. For example, a package named data would be too vague.

- **Prefixes/Suffixes:** If your package is an extension or related to another package, consider using a prefix or suffix. For instance, flask- is a common prefix for Flask extensions (e.g., flask-login).

- **Avoid `Py` Prefix:** While many packages use the "py" prefix to indicate they are Python packages (e.g., pyspark, pytz), it's become somewhat redundant since the package will be on PyPI, and it's understood that it's for Python. However, it's not a strict rule, and some popular packages still use it.

- **Convey Main Benefit or Feature:** If possible, the name should convey the main benefit or feature of the package. For a merge algorithm that's faster, words like "fast", "speed", "quick", "swift", or "turbo" could be part of the name.

So, you can see `PyMerge` broke almost all of these rules and so I settled on the name `mergefast`[^1] which meets all the rules.

<div class="notice--info">

### Setup Your Package Structure

Once you've got a package name chosen, adjust your file structure to match:

~~~{.ini}
mergefast
├── README.md
├── mergefast
│   ├── __init__.py
│   └── core.py
├── setup.py

~~~

Here I've created a `mergefast` folder in my project and created a blank `__init__.py` and then added my `core.py` from above to this folder.

(`setup.py` we cover next.)
</div>

## Creating a Distribution With SetupTools

There are a couple of different paths you can go down when creating a distribution in python. We are going to be using `setuptools`.

Setup tools comes bundled with Python by default, so all we need to do to start is create a `setup.py` file.

~~~{.python caption="setup.py"}
from setuptools import setup

setup(
    name='mergefast',
    version='0.1.3',
    py_modules=['mergefast']
)
~~~

This is most minimal setup.py we can create. More details like description and author can also be added.

## Source Distribution

Next create a source distribution `sdist`:

~~~{.bash caption=">_"}
> python3 setup.py sdist
~~~

You can also do this with `python build` [^2]

~~~{.bash caption=">_"}
> python -m build --sdist
~~~

~~~{.merge-code caption="Output"}
running sdist
...
copying mergefast.egg-info/top_level.txt -> mergefast-0.1.3/mergefast.egg-info
copying tests/__init__.py -> mergefast-0.1.3/tests
copying tests/test.py -> mergefast-0.1.3/tests
Writing mergefast-0.1.3/setup.cfg
Creating tar archive
removing 'mergefast-0.1.3' (and everything under it)
~~~

A `tar.gz` distribution will be produced:

~~~{.ini}
mergefast
├── README.md
├── dist
│   └── mergefast-0.1.3.tar.gz
├── mergefast
├── mergefast.egg-info
│   ├── PKG-INFO
│   ├── SOURCES.txt
│   ├── dependency_links.txt
│   └── top_level.txt
├── setup.py

~~~

### Building the `whl`

We can do the same thing to produce a wheel, which is compiled version of the package.

~~~{.bash caption=">_"}
python3 setup.py bdist_wheel
~~~

Or the newer version of the command

~~~{.bash caption=">_"}
python -m build --wheel
~~~

~~~{.merge-code caption="Output"}
* Creating virtualenv isolated environment...
* Installing packages in isolated environment... (setuptools >= 40.8.0, wheel)
* Getting build dependencies for wheel...
...
adding 'mergefast/__init__.py'
adding 'mergefast/core.py'
adding 'tests/__init__.py'
adding 'tests/test.py'
adding 'mergefast-0.1.3.dist-info/METADATA'
adding 'mergefast-0.1.3.dist-info/WHEEL'
adding 'mergefast-0.1.3.dist-info/top_level.txt'
adding 'mergefast-0.1.3.dist-info/RECORD'
removing build/bdist.macosx-13-arm64/wheel
Successfully built mergefast-0.1.3-py3-none-any.whl
~~~

This gives you a wheel:

~~~{.ini}
.
├── Earthfile
├── README.md
├── build
├── dist
│   ├── mergefast-0.1.3-py3-none-any.whl
│   └── mergefast-0.1.3.tar.gz
├── mergefast.egg-info
│   ├── PKG-INFO
│   ├── SOURCES.txt
│   ├── dependency_links.txt
│   └── top_level.txt
├── setup.py
~~~
<!-- vale HouseStyle.ListStart = NO -->
The name of the generated wheel (`mergefast-0.1.3-py3-none-any.whl`) file tells us a lot about the package:

- **mergefast**: This is the package name.

- **0.1.3:** This is the version number of the package.

- **py3:** This indicates that the package is compatible with Python 3. The package is expected to work with any Python 3 version. If it were py2.py3, that would mean it's compatible with both Python 2 and Python 3.

- **none:** The package does not contain any compiled extensions or is not ABI-specific. ( In [part three](/python-c-extension), you'll see this vary lead to some complications).

- **any:** This denotes the platform. "Any" means the package is platform-independent. ( This will come up in why we build a [Python C extension](/python-c-extension) as well. )
<!-- vale HouseStyle.ListStart = YES -->
Because this wheel works with any platform and any version of Python 3, our source tar is not necessarily needed by PyPi - our compiled wheel should work everywhere.

But, let's test that.

## Testing the Package

Ok, one of the tricky things about distributing your package to PyPI is that once you upload it with a specific version number, you can't change it. The releases are , for practical purposes, immutable.

<div class="align-right">
{% picture content-nocrop {{site.pimages}}{{page.slug}}/5400.png --img width="300px" --alt {{ You can Delete. But don't replace a package. }} %}
<figcaption>You can Delete. But don't replace a package.</figcaption>
</div>

### Delete A Package?

You can delete a released version, if its broken, or yank it, making it inaccessible. The thing you can't do is replace a version number once released.

( There are some build-number based tricks you can find online, but PyPi expects immutable packages, so I'll avoid talking about tricks to side step immutability. )

## Testing: Pip Install Distribution Locally

So you want to make sure your package works before you put it up on PyPI. Ideally you'd want to make sure it works even on different host operating systems. But how can you test the package? Luckily there are several ways to test it.

We can test the source distribution locally, after using pip install:

~~~{.bash caption=">_"}
> pip install ./dist/mergefast-0.1.3.tar.gz
 Processing /dist/mergefast-0.1.3-py3-none-any.whl
 Installing collected packages: mergefast
 Successfully installed mergefast-0.1.3
~~~

Then we can test it with [`test.py`](https://github.com/earthly/mergefast/blob/main/mergefast/tests/test.py) or just jump into the python repl and test it out.

~~~{.bash caption=">_"}
> python test.py
timsort took 5.440176733998669 seconds
mergefast took 3.710623259001295 seconds
~~~

We can test the `whl` the same way.

~~~{.bash caption=">_"}
> pip install mergefast-0.1.3.tar.gz
...
> python test.py
timsort took 5.440176733998669 seconds
mergefast took 3.710623259001295 seconds
~~~

And everything seems to work! But how do we verify that this package is not dependent on some local configuration that I've forgotten to include? It's easy to take things a bit further.

## Earthfile Test

The easiet way to test the package in a repeatable way across architectures and platforms is to use containers. I like to use Earthly for this. All I need to do is wrap the steps we've already covered up into an Earthfile target:

~~~{.dockerfile caption="Earthfile"}
test-dist-tar-install:
    FROM python:3.11-buster
    COPY +build/dist dist
    ENV TARFILE=$(ls ./dist/*.tar.gz)
    RUN pip install "$TARFILE"
    COPY tests .
    RUN python test.py
~~~

In `test-dist-tar-install` I start from a python base image, copy from my [build step]((https://github.com/earthly/mergefast/blob/main/mergefast/Earthfile)), and then install the tar file we build and test it. ( Full Earthfile on [GitHub](https://github.com/earthly/mergefast/blob/main/mergefast/Earthfile). )

Then I can test the package installation at any time by running `earthly +test-dist-tar-install` and seeing the test pass:

~~~{caption="Earthly Output"}
+test-dist-tar-install | --> COPY +build/dist dist
+test-dist-tar-install | --> expandargs ls ./dist/*.tar.gz
+test-dist-tar-install | --> RUN pip install "$TARFILE"
+test-dist-tar-install | Processing /dist/mergefast-0.1.3.tar.gz
+test-dist-tar-install | --> COPY tests .
+test-dist-tar-install | --> RUN python test.py
+test-dist-tar-install | timsort took 6.349711754999589 seconds
+test-dist-tar-install | mergefast took 27.499190239999734 seconds
~~~

I can use the same process to test the wheel:

~~~{.dockerfile caption="Earthfile"}
test-dist-whl-install:
    FROM python:3.11-buster
    COPY +build/dist dist
    ENV WHLFILE=$(ls ./dist/*.whl)
    RUN pip install "$WHLFILE"
    COPY tests .
    RUN python test.py
~~~

And with that I have a truly solid way to test before I push it to PyPI.

## Twine PyPi Push

Ok, let's push it. To push our package, we are going to use [twine](https://PyPI.org/project/twine/).

First thing to do is head to PyPI and setup an API key.

<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/4660.png --alt {{ Head over to PyPi and register an account. }} %}
<figcaption>Head over to [PyPi](https://pypi.org/) and register an account.</figcaption>
</div>

<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/5110.png --alt {{ Create API Token }} %}
<figcaption>Create API Token</figcaption>
</div>
<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/1580.png --alt {{ Get Your Token }} %}
<figcaption>Get Your API Token</figcaption>
</div>

Install twine:

~~~{.bash caption=">_"}
pip install twine
~~~

Setup ENVs for twine with you API Key:

~~~{.bash caption=">_"}
export TWINE_USERNAME=__token__
export TWINE_PASSWORD=**************
~~~

Then use twine to upload:

~~~{.bash caption=">_"}
twine upload --repository-url https://upload.pypi.org/legacy/ dist/*
~~~

~~~
Uploading distributions to https://upload.pypi.org/legacy/
Uploading mergefast-0.1.3-py3-none-any.whl
Uploading mergefast-0.1.3.tar.gz
View at https://pypi.org/project/mergefast/0.1.3/
~~~

For ease of publishing in the future, I put this whole thing in my Earthfile:

~~~{.dockerfile caption="Earthfile"}
twine-publish:
    FROM +build
    COPY +build/dist dist
    RUN --secret TWINE_PASSWORD twine upload --repository-url https://test.pypi.org/legacy/ -u "__token__" -p $TWINE_PASSWORD dist/* 
~~~

## Round Trip Testing

And with that, our package is on PyPI as [mergefast](https://pypi.org/project/mergefast/). We can test it by removing our on package and reinstalling from PyPI:

~~~{.bash caption=">_"}
pip uninstall mergefast --yes
...
pip install mergefast
...
python test.py
 timsort took 5.440176733998669 seconds
 mergeslow took 2.71025900331295 seconds
~~~

Of course, I put this all in my Earthfile as well, for ease of testing:

~~~{.dockerfile caption="Earthfile"}
test-pypi-install:
    FROM python:3.11-buster
    RUN pip install mergefast
    COPY tests .
    RUN python test.py
~~~

And with that we have a published package, that we've tested end to end. There is more to cover though.

If you want to just skip ahead to the final solution, the full code is available on [GitHub](https://github.com/earthly/mergefast/tree/main) and the Earthfile that pulls it all together is [there as well](https://github.com/earthly/mergefast/blob/main/mergefast/Earthfile).

In the [next article](/blog/poetry-publish) in this series, we'll cover:

- Publishing the package with Poetry
- Pushing to test.pypi.com for testing 
- Creating and packaging a Python C extension ([in part 3](/blog/python-c-extension/))

{% include_html cta/bottom-cta.html %}

[^1]: That actual package shown here is being published as `mergeslow`, because well .. it is slow. The fast version is published as `fastmerge` and covered in the third article on packaging c extensions. All code is on [github](https://github.com/earthly/mergefast).

[^2]: See [this blog post](https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html#summary) for details on why this way should be preferred.

</one>
<two>
---
title: "Poetry Build and Publish"
categories:
  - Tutorials
toc: true
author: Adam
sidebar:
  nav: "pypi"
---
https://console.anthropic.com/chat/2c18c217-c3dd-4c70-9caf-9775b9864ced

[Last time](/blog/create-python-package), I walked through packaging a simple Python module using setuptools and setup.py to generate distributions and publish them to PyPI.

Now in Part 2, I'll show you how the Poetry dependency manager and build system simplifies parts of this process. We'll use the same merge sort example code from [Part 1](/blog/create-python-package), but package and distribute it with Poetry instead of setuptools.

Like in Part 1, we'll test the package locally, but we'll also use TestPyPI before publishing to the main package index. Poetry streamlines building and uploading distributions, but the overall workflow remains similar.

By the end, you'll see how both setuptools and Poetry can accomplish the task of packaging and publishing Python projects. To quickly package a Poetry project, just run `poetry publish --build` on a properly configured project. But let's go through the details step-by-step.

## Code

To move our code to Poetry, first we need the same example code from Part 1 that we want to package::

~~~{.python caption="core.py"}
def merge(list1, list2):
    merged_list = []
    i, j = 0, 0
    
    while i < len(list1) and j < len(list2):
        if list1[i] < list2[j]:
            merged_list.append(list1[i])
            i += 1
        else:
            merged_list.append(list2[j])
            j += 1
    
    # Add any remaining elements from list1 or list2
    while i < len(list1):
        merged_list.append(list1[i])
        i += 1
        
    while j < len(list2):
        merged_list.append(list2[j])
        j += 1
    
    return merged_list

~~~

To create a poetry project for this:

~~~{.bash caption=">_"}
> pip install poetry
...
> poetry new mergefast 
Created package mergefast in mergefast
~~~

Doing that creates the structure for my package. Compared to using setuptools directly, Poetry has already initialized the configuration needed to build distributions.

~~~{.ini}
.
├── README.md
├── mergefast
│   └── __init__.py
├── pyproject.toml
└── tests
    └── __init__.py
~~~

For there I just need to copy my code into `core.py` and add my [test.py](https://github.com/earthly/mergefast/blob/v2/mergefast/tests/test.py) into the project.

Let's look at the `pyproject.toml`:

~~~{.toml caption="pyproject.toml"}
[tool.poetry]
name = "mergefast"
version = "0.1.1"
description = ""
authors = ["Adam Gordon Bell <adam@earthly.dev>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
~~~

You can see that name, version, and other details traditionally configured in a setup.py are already here. That makes building the distribution simple.

## Poetry Build

To build a package with poetry:

~~~{.bash caption=">_"}
> poetry build 
Building mergefast (0.1.1)
  - Building sdist
  - Built mergefast-0.1.1.tar.gz
  - Building wheel
  - Built mergefast-0.1.1-py3-none-any.whl
~~~

This will build both a source distribution and a wheel. To build each separately use `poetry build --format sdist` and `poetry build --format wheel`.

## Testing the Package

Because of Poetry's focus on virtual environments, possible to test package without even building it.

~~~{.bash caption=">_"}
> poetry shell
Spawning shell within /Users/adam/Library/Caches/pypoetry/virtualenvs/mergefast.
> pip list
Package            Version   Editable project location
------------------ --------- ---------------------------------------
certifi            2023.7.22
charset-normalizer 3.3.0
docutils           0.20.1
idna               3.4
importlib-metadata 6.8.0
jaraco.classes     3.3.0
keyring            24.2.0
markdown-it-py     3.0.0
mdurl              0.1.2
mergefast          0.1.0     /Users/adam/sandbox/mergefast/mergefast
~~~

<figcaption>Package installed as editable project package inside poetry shell</figcaption>

We can also test the packages the same way as in the [setuptools based article](/blog/create-python-package/), using `pip install mergefast-0.1.1.tar.gz` and using an Earthfile to test installation in a clean container.

That's a great practice. But another testing method available to us it is using `https://test.pypi.org/` to test the publish process end to end.

## Using Test PyPi

<div class="align-right">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/9020.png --picture --img width="300px" --alt {{ Create an account at test.pypy.org }} %}
<figcaption>Create an account at test.pypy.org</figcaption>
</div>
[TestPyPI](test.pypi.org) is a separate instance of the Python Package Index (PyPI) designed specifically for testing and experimentation. It allows developers to practice the process of packaging and publishing their Python projects without affecting the main PyPI repository.

It's basically a staging release location we can use to test things out.

To use TestPyPI, go through the same registration and key creation process as on PyPI.

- Create an Account
- Setup 2-Factor Auth
- Create an API Key

Once you have your API key, poetry can take your API token in `POETRY_PYPI_TOKEN_TESTPYPI`.

~~~{.bash caption=">_"}
export POETRY_PYPI_TOKEN_TESTPYPI=pypi-redacted
~~~

Or it can be passed as a parameter to `poetry publish`, if you indicate `--repository testpypi` :

~~~{.bash caption=">_"}
poetry publish  --repository testpypi -u __token__ -p your_generated_token
~~~

Either way, the key is to tell `poetry publish` to use `--repository testpypi` and your package will publish to [TestPyPi](https://test.pypi.org/project/mergefast/).

~~~{.bash caption=">_"}
> poetry publish --build --repository testpypi -n
There are 2 files ready for publishing. Build anyway? (yes/no) [no] y 
Building mergefast (0.1.1)
  - Building sdist
  - Built mergefast-0.1.1.tar.gz
  - Building wheel
  - Built mergefast-0.1.1-py3-none-any.whl

Publishing mergefast (0.1.1) to PyPI
 - Uploading mergefast-0.1.1-py3-none-any.whl 100%
 - Uploading mergefast-0.1.1.tar.gz 100%

~~~

<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/9660.png --alt {{ Publishing `mergefast` }} %}
<figcaption>Publishing `mergefast`[^1]</figcaption>
</div>

Once that package is up on test PyPI, you can test it end to end with `pip install --index-url https://test.pypi.org/simple/ mergefast`. Or as I'm fond of doing wrapping the whole thing up in a Earthfile target, so I can test it end to end.

~~~{.dockerfile caption="Earthfile"}
poetry-test-publish:
    FROM +build
    RUN poetry config repositories.testpypi https://test.pypi.org/legacy/
    RUN poetry publish --build --repository testpypi -n

test-pypi-install:
    FROM python:3.11-buster
    RUN pip install --index-url https://test.pypi.org/simple/ mergefast
    COPY tests .
    RUN python test.py
~~~

Then I can always test the latest test published package on a clean container like this:

~~~{.bash caption=">_"}
> earthly +test-pypi-install
+test-pypi-install | --> COPY +build/dist dist
+test-pypi-install | --> expandargs ls ./dist/*.tar.gz
+test-pypi-install | --> RUN pip install --index-url https://test.pypi.org/simple/ mergefast
...
+test-pypi-install| --> COPY tests .
+test-pypi-install | --> RUN python test.py
+test-pypi-install | timsort took 6.349711754999589 seconds
+test-pypi-install | mergefast took 27.499190239999734 seconds
~~~

## The Final Poetry Publish

And now that we have tested our package end to end, we can publish it onto [PyPi.org](https://pypi.org/project/mergefast/) with a simple `poetry publish --build`

~~~{.bash caption=">_"}
> poetry publish --build
There are 2 files ready for publishing. Build anyway? (yes/no) [no] y 
Building mergefast (0.1.1)
  - Building sdist
  - Built mergefast-0.1.1.tar.gz
  - Building wheel
  - Built mergefast-0.1.1-py3-none-any.whl

Publishing mergefast (0.1.1) to PyPI
 - Uploading mergefast-0.1.1-py3-none-any.whl 100%
 - Uploading mergefast-0.1.1.tar.gz 100%

~~~

And there you go, the package is published and you have a [repeatable process](https://github.com/earthly/mergefast/blob/v2/mergeslow/Earthfile) for doing so. For Python only packages, `poetry publish` is a simple way to go. No need for setuptools and `setup.py` at all.

For a simple package like this, this whole testing workflow might be overkill. But if your package has users and you want to make sure you don't break their workflow I think it makes sense to sanity test your packages.

## Next Up: C Extensions

Next up, let's tackle the c version of this code and publish a python c extension on to PyPi. Publishing a native extension is a bit trickier, but we now have the skills to easily tackle this problem. The testing setup we've established here, with Earthly and test.pypy.org and our knowledge of poetry and setup tools will all come together in [part three](/blog/python-c-extension/)

There is not a lot of ways for packaging to wrong with a single file package, but in the next article, testing end to end is will really pay off.

[^1]: That actual current version of `mergefast` is published in [packaging c extensions](/blog/python-c-extension/). This python only implementation is published as `mergeslow`. Both and full source is on [github](https://github.com/earthly/mergefast).

{% include_html cta/bottom-cta.html %}

</two>

<three>
---
title: "Python C Extension pypi Package"
categories:
  - Tutorials
toc: true
author: Adam
sidebar:
  nav: "pypi"
---

In Article 1 of this series, I showed you how to [package and distribute pure Python code using setuptools and a setup.py file](/blog/create-python-package/). Then in Article 2, we looked at how the [Poetry tool simplifies this process](/blog/poetry-publish/) for pure Python packages. In this final article, we'll tackle distributing a Python package containing a C extension, which adds some extra complexity. 

## Why a C Extension

In the previsous articles we published `mergefast` and I claimed the Python code shown was a performant merging algorithm. That was a fib - the pure Python implementation is actually slower then just resorting the list. ( [Background](/blog/python-timsort-merge). )

I did this to set up the need for a C extension. To make mergefast fast, we need to write it as a c extension, which significantly complicates publishing. But now we are ready to tackle publishing a C extension to PyPi.

Let's get started...

## The Code

To start, let's look at the code we want to package up. In the previous articles we had some Python code that looked like:

```
def merge(list1, list2):
  # standard merge sorted lists with pop algo
```

By implementing this in C, we can achieve much faster performance than in Python. But, the specifics of the C porting aren't the point today. The packaging is.

To integrate this C extension into Python, we need a header file.

~~~{.c caption="core.h"}
PyObject* merge( PyObject*, PyObject* );
~~~

<figcaption>Here is a our header. ( [full source](https://github.com/earthly/mergefast/tree/v2/mergefast) )</figcaption>

We also need a bind.c, where there are a lot of little details to get right. Lets go slowly through them, as this is where I initially got stuck.

### 1. Declaring Our PyMethodDef Function

~~~{.c caption="bind.c"}
#include "core.h"

PyMethodDef merge_funcs[] = {
    {
        "merge", /* function name */
        (PyCFunction)merge,
        METH_VARARGS,
        "merge two sorted lists" /* function docs */
    },
    { NULL }
};
~~~

- We declare an array of `PyMethodDef` structures named `merge_funcs`.
- Each `PyMethodDef` structure represents a method that will be made available in our Python module. We just have one for now.
- The structure has the following elements:
  - `"merge"`: The name of the function as it will appear in Python.
  - `(PyCFunction)merge`: The actual C function that implements this method.
  - `METH_VARARGS`: A flag indicating the calling convention of our function.
  - `"merge two sorted lists"`: A documentation string for the function.
- The `{ NULL }` entry serves as a sentinel, signaling the end of the method definitions.

### 2. Defining Our Module

~~~{.c caption="bind.c"}
PyModuleDef merge_mod = {
    PyModuleDef_HEAD_INIT,
    "core", /* library name */
    "core module", /* module docs */
    -1,
    merge_funcs,
    NULL,
    NULL,
    NULL,
    NULL
};
~~~

- Next we define a module (`PyModuleDef`) structure named `merge_mod` representing the module we are creating.
- `PyModuleDef_HEAD_INIT`: A required boilerplate initialization.
- `"core"`: The name of our module.
- `"core module"`: A documentation string for our module.
- `-1`: Refers to the size of the module state in bytes, with `-1` indicating module-level state only.
- `merge_funcs`: The previously defined array of methods.

Everything, after that is optional, so we pass NULL for now.

### 3. Defining Our Init Function

~~~{.c caption="bind.c"}
PyMODINIT_FUNC PyInit_core( void )
{
    return PyModule_Create( &merge_mod );
}
~~~

Next up is Init. And guess what, it initializes our module.

- `PyMODINIT_FUNC` is a macro that ensures that the function has the correct return type and visibility to be used as a module initialization function.
- `PyInit_core`: The name is significant. If our module is named "X", then the initialization function must be named `PyInit_X`.

Python calls this when the module is imported. We then use `PyModule_Create` to create and return a new module object based on our `merge_mod` definition above.

## C Extension Building With SetupTools

Now we are ready to build our extension. Even though we are using poetry, which has a nice built in build and publish functionality, I found using setup tools directly with a setup.py the easiet way to build.

( It's possible to configure some of setuptools via pyproject.toml, but it's tricky and beyond our scope here. )

So, create a `setup.py`:

~~~{.c caption="setup.py"}
from setuptools import setup, Extension, find_packages

merge_module = Extension(
    "mergefast.core",
    sources=["mergefast/bind.c", "mergefast/core.c"],
    include_dirs=["mergefast"],
    extra_compile_args=["-O3"]
)
~~~

1. **`"mergefast.core"`**:

   This is the name of the extension module we are building. `mergefast.core` will be a submodule of `mergefast`.

1. **`sources=["mergefast/bind.c", "mergefast/core.c"]`**:

  These are the source files that need to be compiled to produce or extension.

1. **`include_dirs=["mergefast"]`**:

   This specifies directories where the compiler should look for header files during the compilation process. Without this `core.h` won't be found.

1. **`extra_compile_args=["-O3"]`**:

   Here we are just using the `-O3` flag to apply high-level optimizations to improve performance. We are aiming for maximum execution speed.
  
Next, we call `setup()`:

~~~{.python caption="setup.py"}
setup(
    name="mergefast",
    version="1.1.3",
    packages=find_packages(),
    ext_modules=[merge_module],
)
~~~

Most of this is straight-forward. The first two lines, we are naming our package and versioning it. `ext_modules=[merge_module]` tells setuptools to compiler our `mergefast.core` package previously defined.

The third line, `packages=find_packages()`, is a bit trickier. The find_packages() function is a utility from setuptools that automatically discovers all Python packages in your project directory. This is essential for getting our `__init__.py` file into the final package.

Our `__init__.py` imports core, so `import mergefast.merge` works and without `find_packages()` it won't be included in our package.

~~~{.python caption="__init__.py"}
from mergefast.core import merge_int, merge_float, merge_latin, merge

~~~

Without that, our package will work fine locally as a project location based package in poetry, but `import mergefast` won't work when install as a package.

( Highlighting the value of testing the package installation process. )

## Build and Test in Place

With that setup.py setuptools code in place, we can compile and test our solution.

~~~{.bash caption=">_"}
> poetry install
Installing dependencies from lock file
...
> poetry shell
Creating virtualenv mergefast-95GN-TFI-py3.11 in /Users/adam/Library/Caches/pypoetry/virtualenvs
Spawning shell within /Users/adam/Library/Caches/pypoetry/virtualenvs/mergefast-95GN-TFI-py3.11
Traceback (most recent call last):
  File "/Users/adam/sandbox/mergefast/mergefast/tests/test.py", line 1, in <module>
    import mergefast
  File "/Users/adam/sandbox/mergefast/mergefast/mergefast/__init__.py", line 1, in <module>
    from mergefast.core import merge_int, merge_float, merge_latin, merge
ModuleNotFoundError: No module named 'mergefast.core'
~~~

Oh no. More work to do. You see we have our `mergefast` package, but we need to compile our `core` module.

~~~{.bash caption=">_"}
> python setup.py build_ext --inplace
python setup.py build_ext --inplace
running build_ext
building 'mergefast.core' extension
creating build
creating build/temp.macosx-13-arm64-cpython-311
creating build/temp.macosx-13-arm64-cpython-311/mergefast
clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk -Imergefast -I/Users/adam/Library/Caches/pypoetry/virtualenvs/mergefast-95GN-TFI-py3.11/include -I/opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c mergefast/bind.c -o build/temp.macosx-13-arm64-cpython-311/mergefast/bind.o -O3
clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk -Imergefast -I/Users/adam/Library/Caches/pypoetry/virtualenvs/mergefast-95GN-TFI-py3.11/include -I/opt/homebrew/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c mergefast/core.c -o build/temp.macosx-13-arm64-cpython-311/mergefast/core.o -O3
creating build/lib.macosx-13-arm64-cpython-311
creating build/lib.macosx-13-arm64-cpython-311/mergefast
clang -bundle -undefined dynamic_lookup -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk build/temp.macosx-13-arm64-cpython-311/mergefast/bind.o build/temp.macosx-13-arm64-cpython-311/mergefast/core.o -o build/lib.macosx-13-arm64-cpython-311/mergefast/core.cpython-311-darwin.so
copying build/lib.macosx-13-arm64-cpython-311/mergefast/core.cpython-311-darwin.so -> mergefast
~~~

And then we test run our c based merge

~~~{.bash caption=">_"}
python tests/test.py
timsort took 2.2706818750011735 seconds
merge took 2.0606187919911463 seconds
~~~

And we are faster then [timsort](/blog/python-timsort-merge)!

## Binary Package Woes

It's worth noting the above build produces `core.cpython-311-darwin.so` on my M1 mac. It will produce something different if you are on windows or linux and this adds challenges when it becomes time to produce our `.whl`.

~~~{.bash caption=">_"}
> python setup.py bdist_wheel
running bdist_wheel
running build
running build_py
...
creating 'dist/mergefast-1.1.3-cp311-cp311-macosx_13_0_arm64.whl'
~~~

The created wheel file is `mergefast-1.1.3-cp311-cp311-macosx_13_0_arm64.whl`

Because the c extension functionality is closely tied to the python version, this shared object file is just for 3.11 `cp311-cp311`. And because this wheel contains native code, its specific to the OS and architecture its compiled for (`macosx_13` and `arm64`).

Want to pip install from PyPi on different systems, like not arm64 or not macOS x? Good news: You just have to build a wheel for each system and then upload them all. But, there's a catch. Even with things like `manylinux`, you'll need the right machines. Virtual or real ones with the systems you're building for.

Many use GitHub actions matrix builds to accomplish this:

~~~{.yaml caption="workflow.yaml"}
  build_wheels:
    name: Build wheels on ${{ matrix.os }}  - ${{ matrix.vers }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - vers: i686
            os: ubuntu-20.04
          - vers: aarch64
            os: ubuntu-20.04
          - vers: auto64
            os: ubuntu-20.04
          - vers: arm64
            os: macos-10.15
          - vers: auto64
            os: macos-10.15
          - vers: auto64
            os: windows-2019
~~~

<figcaption>matrix wheel build of [poloaroid](https://github.com/Daggy1234/polaroid/blob/main/.github/workflows/publish.yml) package.</figcaption>

Let's skip all that for now, though, by doing a source build.

## Source Build to the Rescue

When you use pip install, pip picks the best format for your package. It likes wheels because they often have pre-compiled code. This makes installation faster and skips the build step.

If pip can't find a wheel, it uses the source distribution and compiles during installation.

The downside? The user needs a C compiler. But, as long as you have the python.h header file, that's the only constraint for our small extension. No need for a complex matrix build. Let's proceed with that approach.

~~~{.bash caption=">_"}
> python3 setup.py sdist
...

producing mergefast-1.1.3.tar.gz
~~~

We can test this package with a `pip install dist/mergefast-1.1.3.tar.gz`. I, of course, do this [Earthly](/), for reproducibility sake:

~~~{.dockerfile caption="Earthfile"}
test-dist-install:
    FROM python:3.11-buster
    COPY +build/dist dist
    ENV TARFILE=$(ls ./dist/*.tar.gz)
    RUN pip install "$TARFILE"
    COPY tests .
    RUN python test.py

~~~

Which gives:

~~~
> pip install dist/mergefast-1.1.3.tar.gz
 Building wheel for mergefast (pyproject.toml) did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      running bdist_wheel
      ... 
      gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -Imergefast -I/usr/local/include/python3.11 -c mergefast/bind.c -o build/temp.linux-x86_64-cpython-311/mergefast/bind.o -O3
      mergefast/bind.c:1:10: fatal error: core.h: No such file or directory
       #include "core.h"
~~~

Failure! You can see that on installation pip runs the `bdist_wheel` process which works ok, until we try to include our header file core.h.  

## MANIFEST.in

You see, the python `sdist` process knows to include all the python files in a package into the source distribution, but it really has no idea about what other files are needed to build the project. In my perfect world, it would be able to infer from some heuristics to include_dirs=["mergefast"].

That's not the world we live in though, so setuptools supports a `MANIFEST.in` file, where you describe all the extra files your package needs.

~~~{.ini caption="MANIFEST.in"}
include mergefast/*.c
include mergefast/*.h
include mergefast/*.py

~~~

With that in place, installing from a source distribution works:

~~~
  > earthly +test-dist-install
  ...
  +test-dist-install | --> RUN python test.py
  +test-dist-install | timsort took 5.315027578999434 seconds
  +test-dist-install | merge_int took 1.7830523350021394 seconds
  +test-dist-install | merge took 4.74845955499768 seconds
~~~

Now all I need to do is publish:

~~~{.bash caption=">_"}
> poetry publish -n
Publishing mergefast (1.1.3) to pypi
 - Uploading mergefast-1.1.3.tar.gz 100%
~~~

And just like that we have our package on PyPi:

<div class="wide">
{% picture content-wide-nocrop {{site.pimages}}{{page.slug}}/9880.png --alt {{ package on pypi }} %}
<figcaption>[And it's up](https://pypi.org/project/mergefast/)</figcaption>
</div>

( If you'd like to see how to test the package before pushing see the earlier article on [TestPyPi(/blog/poetry-publish).)

## Conclusion

In this final article, we saw how packaging a C extension requires extra configuration compared to pure Python. All the code for `mergefast`, and its earlier python implementation `mergeslow` are up on [github](https://github.com/earthly/mergefast). 

Of course, I have wrapped all these stages of building, local package installing, pushing to TestPyPi and pushing to actual PyPi in Earthfile targets. That way I don't need to head back to this tutorial each time to remember how to run each step.

I hope this three part series is useful. This last stage, the python extension packaging was the most involved, but with the necessary background it all makes sense.

It goes to show that behind the ease of `pip install` there is lots of unsexy but needed packaging, building and distribution work happening.  

( Take a look at the pip packaging code for a lib like [TensorFlow](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/pip_package) sometime to see how complex things can get. )

And if you want to know about the next article in the series, subscribe to the newsletter. I'm probably going to attempt a python extension in Rust soon.

{% include_html cta/bottom-cta.html %}

</three>

Focusing on the structure of the articles, what problems do you see that could be improved? I'd like some high level feed back on what sections could be improved or removed or rearranged or what is missing.
